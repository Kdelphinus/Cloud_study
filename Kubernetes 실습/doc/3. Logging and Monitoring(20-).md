# Logging and Monitoring (Section 20 - )

## Section 20: Kubernetes Cluster Logging

- 우리가 수동으로 로그를 확인할 때는 대체로 클러스터를 구성하고 실행하는 단계였다.
- 하지만 클러스터가 정상 동작을 할 때도 로그를 파악한다면 여러 정보를 얻을 수 있다.
- 그러나 로그가 너무 많기 때문에 포드 하나씩 로그를 직접 살펴볼 수는 없다.

### ELK 스택(Elastic Stack) 개념

#### 구성 서비스

1. Logstash or Fluentd

- 노드에 컨테이너들이 있을 때, 컨테이너들은 로그를 쓴다. 이러한 로그들을 모으는 프로그램이 logstash이다.
- 같은 노드에서 컨테이너로 존재한다.
- Fluentd 역시 Logstash와 동일한 역할을 수행하며 둘 중의 하나를 선택하는 형태로 스택이 구성된다.

2. Elasticsearch

- 엘라스틱서치는 분산 서치이고 분석 엔진이다.
- 즉, 엘라스틱서치로 어떤 데이터라도 엘라스틱서치 데이터베이스에 저장하고 쿼리할 수 있다.
- 서치 엔진 실행 파트로 봐도 된다.

3. Kibana

- 엘라스틱서치의 데이터를 시각화 해주는 도구다.
- 그래프, 차트 등 데이터를 정제하고 시각화하는 다양한 기능들이 있다.

#### 클러스터 설치

- 로그스태시는 클러스터에 있는 모든 싱글 노드에 설치해야 한다.
- 엘라스틱서치와 키바나는 원하는 방식으로 구성할 수 있다.
  - aws는 엘라스틱서치 서비스를 지원한다. 이를 통해 구성할 수도 있다. 이는 클러스터 밖에서 안정적이고 강력하게 실행할 수 있다는 장점이 있다.
  - 키바나는 웹 앱이기에 어느 곳에든 설치할 수 있다. 오직 키바나만 실행되는 ec2 인스턴스를 설정할 수도 있다.
  - 간단하고 빠르고 지저분한 방법은 쿠버네티스 클러스터에 직접 배포하는 방법이다.
    - 플루언티드는 각 노드에 설치되어야 한다.
    - 엘라스틱서치는 시스템에 적어도 2개의 노드에서 복제되도록 만들어 엘라스틱서치 서비스가 중단되지 않고 로그가 저장되지 않는 것을 방지한다.
    - 키바나는 임의의 싱글 노드에 설치한다.
    - 이 방법은 새로운 인스턴스를 사용하지 않기 때문에 간단하고 빠르다.
    - 하지만 노드에 포드가 계속해서 추가되기에 잠재적으로 노드에 과부하를 계속 준다.


### ELK 스택 설치

- 강사가 제공한 `elastic-stack.yaml` 과 `fluentd-config.yaml` 은 kubernetes 레포지토리에서 addon 폴더 안에 있는 것 중 fluentd 관련 배포 파일을 간략하게 만든 것이다.
- 이 두 파일을 ec2에 복사해서 배포하면 여러 포드들이 만들어지지만 `kubectl get po` 와 같은 명령어에서 잡히지 않는다.
- 왜냐하면 elk 스택은 `kube-system` 이라는 네임스페이스에 배포되었기 때문이다.
- 따라서 `kubectl get po -n kube-system` 명령어를 사용하면 다른 쿠버네티스 시스템 포드와 함께 동작 중임을 확인할 수 있다.

```Shell
NAME                                  READY   STATUS    RESTARTS   AGE
aws-node-6jtwf                        2/2     Running   0          43m
aws-node-fnmqk                        2/2     Running   0          43m
aws-node-j57fc                        2/2     Running   0          43m
coredns-f94fb47d9-9xx5j               1/1     Running   0          49m
coredns-f94fb47d9-br5bz               1/1     Running   0          49m
ebs-csi-controller-74dc77bcd9-hqt4c   6/6     Running   0          38m
ebs-csi-controller-74dc77bcd9-v7chw   6/6     Running   0          38m
ebs-csi-node-78gfv                    3/3     Running   0          38m
ebs-csi-node-b8s5c                    3/3     Running   0          38m
ebs-csi-node-qpwlq                    3/3     Running   0          38m
elasticsearch-logging-0               1/1     Running   0          3m47s
elasticsearch-logging-1               1/1     Running   0          3m14s
fluentd-es-v2.2.0-j8mk2               1/1     Running   0          3m47s
fluentd-es-v2.2.0-t5lpm               1/1     Running   0          3m47s
fluentd-es-v2.2.0-t9fdh               1/1     Running   0          3m47s
kibana-logging-758ff4b89f-5mmhj       1/1     Running   0          3m47s
kube-proxy-phpn5                      1/1     Running   0          43m
kube-proxy-rtmnr                      1/1     Running   0          43m
kube-proxy-vx9h7                      1/1     Running   0          43m
```

- 결과를 보면 `elasticsearch-logging-0/1` 이 생긴 것과 `fluentd` 가 각 노드별로 하나씩 총 3개가 생긴 것, `kibana` 가 생성된 것을 확인할 수 있다.
- `kubectl get svc -n kube-system` 명령어로 서비스를 확인하면 기존에 있는 `kube-dns` 말고 두 개가 더 생긴 것을 확인할 수 있다.

```Shell
NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP                                                                    PORT(S)                  AGE
elasticsearch-logging   ClusterIP      10.100.246.176   <none>                                                                         9200/TCP                 10m
kibana-logging          LoadBalancer   10.100.81.208    af59dff7d9f4b45889c536d218a177e0-1529305552.ap-northeast-2.elb.amazonaws.com   5601:32269/TCP           10m
kube-dns                ClusterIP      10.100.0.10      <none>                                                                         53/UDP,53/TCP,9153/TCP   56m
```

- `elasticsearch-loggin` 은 외부 ip없이 내부에서만 소통한다.
- `kibana-logging` 은 프론트 포드이기에 외부에서 접근할 수 있는 ip도 존재한다.
- `kubectl describe svc kibnan-logging -n kube-system` 명령어로 어떤 로드밸런서를 사용하는지 확인 후, 로드 밸런서 페이지에서 이를 확인한다.
- 로드 밸런서의 리스너를 살펴보면 프로토콜 포트에 할당된 포트를 확인할 수 있다. {로드밸런서 dns 이름}:{포트} 로 키바나 서비스에 접근할 수 있다.

### Kibana 사용

- 우선 우리는 Logging은 할 필요가 없다. 이미 엘라스틱 서치가 로깅을 하고 있다.
- 먼저 `Set up Index pattern` 에 들어가서 Index pattern을 정의한다.
  - logstash가 작동될 때 자동으로 엘라스틱 서치 인덱스를 생성한다.
  - 이때 이름은 `logstash-{날짜}` 인데 플루언티드가 인덱스로 logstash를 사용하는 이유는 호환성 때문일 것이다.
  - 그렇기에 날짜가 지날 때마다 인덱스가 계속 추가된다.
  - 정의 방법
    - 먼저 인덱스 패턴을 `logstash*` 으로 하여 자동으로 생성되는 인덱스를 하나로 묶는다.
    - 다음으로 플루언티드는 자동으로 모든 싱글 로그에 타임스탬프를 추가한다. 우리는 이 타임을 기반으로 해서 키바나가 데이터를 사용하도록 설정한다.
    - 이를 통해 인덱스 패턴을 생성한다.
- Discover 탭에 들어가면 검색 엔진을 볼 수 있다. 기본값은 검색 엔진에 아무것도 추가하지 않았기에 엘라스틱 서치에 있는 모든 데이터가 보여진다.
  - 예를 들어 'error' 를 검색하면 로그에 error가 찍힌 것들을 모아 볼 수가 있다.
  - 나온 결과를 클릭하면 다양한 정보들이 나오는데 `kubernetes.container_name` 으로 로그가 발생한 컨테이너의 이름을 알 수 있고 그 외에도 다양한 정보들이 기록되어 있다.
  - 또한 원본 로그 메시지 역시 확인할 수 있다.
  - 필터를 걸 수도 있는데 예를 들어 우리가 만든 앱에 관련된 로그만 확인하고 싶다면 `kube-system` 네임스페이스 결과를 제외해야 한다.
  - 이를 위해 'Add a filter' 버튼을 누르고 필터에서 `kubernetes.namespace_name` 을 선택해서 제외하거나 원하는 것만 나오게 만들 수 있다.
  - 또한 'Available Fields' 를 눌러 저장된 모든 필드를 확인할 수 있으며 각 필드별로 어떤 값이 어떤 비율로 분포하는지 간단하게 확인할 수 있다.
    - 이때 값에 있는 플러스 돋보기를 누르면 필터에 자동으로 추가된다.
  - 오류가 발생했을 때도 로그가 계속 쌓이기 때문에 굳이 쿠버네티스 시스템에 접속하지 않고도 문제를 확인할 수 있다.
  - 또한 필터의 설정을 저장하고 불러올 수 있다.
- Visualize 탭에 들어가면 여러 방식의 시각화를 만들 수 있다.
  - 예를 들어 Gauge 형식을 사용하면 네임스페이스나 저장된 필터 설정 중 하나를 고를 수 있다.
  - 이를 선택하면 그에 해당하는 로그가 발생한 횟수를 알려주는 시각화 데이터가 나온다.
  - 위에 시작 버튼을 누르면 주기적으로 새로고침을 하며 데이터를 확인할 수 있다.
  - 저장하여 대시보드에 추가할 수 있다.


## Section 21: Monitoring a Cluster

- 노드에 대한 모니터링은 aws를 사용한다면 기본적으로(무료) 인스턴스를 선택하고 모니터링 탭을 확인하면 존재한다.
  - 그리고 더 자세하게 분석을 제공하는 서비스가 있지만 이는 추가 요금이 발생한다.
- 이를 사용해도 되지만 클라우드를 옮기거나 할 때, 새로운 서비스에 다시 익숙해져야 하는 등의 단점이 발생한다.
- 그렇기에 자체 모니터링 서비스를 사용할 계획이다. 이는 더 다양한 모니터 테이블, 자체 알림 서비스까지 만들 예정이다.
- 다양한 도구들이 있지만 쿠버네티스에서 가장 많이 사용하는 것은 **프로메테우스** 다.

### Prometheus & Grafana

- 프로메테우스는 수많은 데이터를 모으는 역할을 한다.
- 그리고 그래픽 도구로 가장 흔히 사용되는 것이 그라파나이다.
- 이 두 개를 사용하는 것은 매우 흔하지만 이 서비스는 쿠버네티스만을 위한 서비스는 아니기에 이를 직접 구성하는 것은 깊고 어려운 주제이다.
- 그렇기에 이 강의에선 미리 만들어진 스택을 사용할 것이다.
  - 과거에는 [helm/charts github](https://github.com/helm/charts) 레포지토리 안에 stable/prometheus-operator 라는 스택을 사용했었다.
  - 그러나 이것이 prometheus-community로 옮겨가면서 현재는 [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)를 사용해야 한다.
  - 이 자체도 굉장히 깊은 내용이기에 강의에선 yaml 파일이 제공된다.

### Prometheus

- `crds.yaml` 파일은 공통 파일로 수많은 것들이 정의되어 있다.
- 그리고 다른 파일은 eks와 kops 중 어떤 것을 사용하느냐에 따라 둘 중 한 파일을 사용해야 한다.
  - 두 개의 차이를 둔 이유는 알림에서 약간의 차이가 있기 때문이고 이는 다음 섹션에서 확인할 예정이다.
  - 또한 eks는 마스터 노드가 없기에 접근할 필요가 없다. 허나 kops는 마스터 노드가 있기에 마스터 노드가 충돌되거나 잘못된 접근을 했을 때 알림이 필요하다.
- 주의할 점은 `crds.yaml` 파일을 무조건 먼저 적용해야 한다는 것이다. 먼저 적용을 마친 뒤, `monitoring.yaml` 파일을 적용해야 한다.

- 허나 직접 배포해보면 에러가 발생하고 'monitoring' 네임스페이스 안에 생성되지도 않는다.
- 그렇기에 아래는 강의가 아니라 직접 helm을 설치해 진행한 것이다.
- stack 설치는 [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)와 [블로그](https://leehosu.github.io/kube-prometheus-stack)를 참고했다.

```Shell
# helm 설치
$ curl -sSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash

# 설치 버전 확인
$ helm version --short
```

```Shell
# monitoring이란 네임스페이스 생성
$ kubectl create ns monitoring
```

```Shell
# 헬름 차트의 저장소 추가
$ helm repo add prometheus-community https://prometheus-community.github.io/
$ helm repo update
```

```Shell
# helm chart 배포
$ helm install prometheus -n monitoring prometheus-community/kube-prometheus-stack
```

```Shell
# service 확인
$ kubectl get svc -n mornitoring
NAME                                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
alertmanager-operated                     ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP   19s
prometheus-grafana                        ClusterIP   10.100.89.202    <none>        80/TCP                       22s
prometheus-kube-prometheus-alertmanager   ClusterIP   10.100.37.222    <none>        9093/TCP,8080/TCP            22s
prometheus-kube-prometheus-operator       ClusterIP   10.100.205.56    <none>        443/TCP                      22s
prometheus-kube-prometheus-prometheus     ClusterIP   10.100.191.234   <none>        9090/TCP,8080/TCP            22s
prometheus-kube-state-metrics             ClusterIP   10.100.62.196    <none>        8080/TCP                     22s
prometheus-operated                       ClusterIP   None             <none>        9090/TCP                     19s
prometheus-prometheus-node-exporter       ClusterIP   10.100.126.102   <none>        9100/TCP                     22s
```

- 동작되는 서비스 중에서 `alertmanager-operated` 같은 경우는 알림, `prometheus-kube-prometheus-prometheus` 는 자체 프론트를 지원한다.
- 만약 테스트를 위해 프로메테우스에 직접 접근해야 한다면 프로메테우스-프로메테우스에 접근해야 한다. 하지만 ClusterIP이기에 외부에서 접근할 수 없다.
- 이를 바꾸기 위해 로드 밸런서를 사용하면 빠르고 간편하지만 약간의 비용이 발생한다.
- 이번엔 로드 밸런서를 사용하는 방법말고 다른 방법을 사용한다.

```Shell
# prometheus-kube-prometheus-prometheus 서비스를 수정하는 명령어
$ kubectl edit svc prometheus-kube-prometheus-prometheus -n monitoring
```

- 허나 이 방법은 좋지는 않다. 실행되는 환경과 yaml 파일 간의 간극이 생기는 것이기 때문이다.
- 그렇기에 클러스터를 삭제했다가 다시 적용했을 때, edit 명령어는 적용되지 않은 상태일 것이다.
- 그렇기에 일시적으로 정확히 아는 상태에서만 사용해야 한다.

```yaml
...
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
```

- 가장 아래로 내려가면 위와 같이 ClusterIP로 되어있을 것이다. 이를 아래와 같이 수정한다.

```yaml
...
  sessionAffinity: None
  type: LoadBalancer
status:
  loadBalancer: {}
```

- 저장하고 나가면 적용되는데 만약 오타나 없는 명령어를 사용하면 다시 편집기로 돌아온다.
- 다시 서비스 목록을 출력하면 아래와 같이 로드 밸런서로 변한 것을 확인할 수 있다.

```Shell
$ kubectl get svc -n mornitoring
NAME                                      TYPE           CLUSTER-IP       EXTERNAL-IP                                                                   PORT(S)                         AGE
alertmanager-operated                     ClusterIP      None             <none>                                                                        9093/TCP,9094/TCP,9094/UDP      12m
prometheus-grafana                        ClusterIP      10.100.89.202    <none>                                                                        80/TCP                          12m
prometheus-kube-prometheus-alertmanager   ClusterIP      10.100.37.222    <none>                                                                        9093/TCP,8080/TCP               12m
prometheus-kube-prometheus-operator       ClusterIP      10.100.205.56    <none>                                                                        443/TCP                         12m
prometheus-kube-prometheus-prometheus     LoadBalancer   10.100.191.234   a433cb10462a1460ca59e24fe94d0fa9-726087349.ap-northeast-2.elb.amazonaws.com   9090:30435/TCP,8080:30872/TCP   12m
prometheus-kube-state-metrics             ClusterIP      10.100.62.196    <none>                                                                        8080/TCP                        12m
prometheus-operated                       ClusterIP      None             <none>                                                                        9090/TCP                        12m
prometheus-prometheus-node-exporter       ClusterIP      10.100.126.102   <none>                                                                        9100/TCP                        12m
```

- 로드 밸런서의 이름이 있으니 저 주소에 포트를 9090으로 하여 접속하면 프로메테우스 프론트에 접근할 수 있다.
- 프로메테우스엔 여러 매트릭스를 설정할 수 있는데 그 중 `node_load1/5/15` 가 있다. 이는 1/5/15분 직전의 cpu 평균 로드를 나타낸다.
- 매트릭스를 선택하고 그래프를 클릭하면 값들에 대한 그래프를 볼 수 있다.
- 하지만 우리는 프로메테우스를 프론트로 이용할 계획이 없으니 다시 `ClusterIP` 로 복구할 것이다.

### Grafana

- 일반적인 목적의 그래픽 도구이자 다양한 데이터 소스에 연결될 수 있다.
- 이미 목록에 `prometheus-grafana` 가 있다. 우리는 이에 접근할 수 있도록 `LoadBalancer` 로 바꿀 것이다.
- 바꾸는 방법은 위와 같이 `edit` 명령어를 사용한다.
- 80포트이기에 따로 포트를 지정할 필요는 없고 몇 분 정도 기다리면 그라파나에 접속할 수 있다.

- 기본 계정은 다음과 같다.(깃허브에 정보 있음)
  - id: admin
  - pw: prom-operator
- 스택에 이미 정의된 대시보드가 많다.
- 우리는 이중에 `USE Method/Node` 와 `USE Method/Cluster` 를 살펴볼 것이다.
  - U: Utilisation(이용, 특정 리소스가 얼마나 사용되는가)
  - S: Saturation(포화, 특정 리소스가 얼마나 오버로드 되는가)
  - E: Errors(에러, 예상치 못한 동작)
- 대시보드에 들어가면 바로 그래픽이 나타난다.
- USE 메소드 노드
  - 노드는 각 인스턴스 별로 나타나며 개인 IP로 식별하면 된다.
  - 이때 새로고침을 걸어두면 클러스터에 부하가 갈 수 있다. 괜찮은 성능이면 상관없지만 이미 어느 정도 부하가 있는 클러스터라면 더 악화시킬 수 있다.
  - 하지만 각 노드별로 확인해야 하기에 불편하다.
- USE 메소드 클러스터
  - 각 노드가 겹쳐서 나오기에 노드 별로 비교하기가 쉽다.
- Persistent Volumes
  - 시스템에 정의된 모든 퍼시스턴트 볼륨을 확인할 수 있다.