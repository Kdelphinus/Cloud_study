# Going Further with Kubernetes(Section 25 - 33)

## Section 25: Requests and Limits

### Resource Requests

- 포드를 정의할 때 명시할 수 있다.
- 뭘 요청하냐에 따라 메모리 요청이나 CPU 요청이 될 수 있다.

#### Memory Request

- 만약 우리가 만든 큐에서 특정 이상의 메모리가 필요하다고 하면 우리는 yaml 파일에서 컨테이너 블록 안에 필요한 사양을 명시할 것이다.

```yaml
...
  template: # template for the pods
    metadata:
      labels:
        app: queue
    spec:
      containers:
      - name: queue
        image: richardchesterwood/k8s-fleetman-queue:release2
        resources:
          requests:
            memory: 300M  # 1Mi = 1024ki, 1ki = 1024 bytes
```

- 이렇게 요청을 적는 것은 권장되는데 이는 노드에 포드를 배치할 때 유용하기 때문이다.
- 이를 통해 1기가 메모리를 가진 노드에는 300메가 메모리가 필요한 포드를 3개만 배치하게 된다.
- 만약 이를 명시하지 않으면 노드에 포드 4개를 배치하려 할 것이고 이는 다른 3개의 포드에도 영향을 주게 된다.

- 노드의 사양을 알아보기 위해 다음과 같은 명령어를 사용한다.

```Shell
# 동작하는 kubernetes 노드 이름 확인
$ kubectl get nodes
```

```Shell
# 노드 사양 출력
$ kubectl describe node {node name}
...
Capacity:  # kubernetes에 할당된 사영
  cpu:                8  # 8개의 cpu 사용 가능
  ephemeral-storage:  61202244Ki
  hugepages-2Mi:      0
  memory:             8028408Ki  # 약 7.6 Gi
  pods:               110
Allocatable:  # 포드에 할당할 수 있는 사양
  cpu:                8
  ephemeral-storage:  56403987978
  hugepages-2Mi:      0
  memory:             7926008Ki
  pods:               110
...
```

- 그러먄 위처럼 `Capacity` 와 `Allocatable` 블록을 확인할 수 있다.
- `Capacity` 는 쿠버네티스에 할당된 사양이고 `Allocatable` 은 실제 포드에 할당할 수 있는 사양이다.
- 이를 토대로 메모리에 3000Mi를 요청하고 메모리가 감당할 수 있는 메모리를 넘어섰을 때 반응을 살펴볼 것이다.

```Shell
$ kubectl apply -f resource-testing.yaml
```

- 배포된 것을 확인할 수 있다.
- 하나가 배포된 것을 확인했으니 yaml 파일에 `replicas` 항목을 2로 늘리고 실행한다.
- 그리고 노드 사양을 다시 출력하면 밑에 다음과 같은 출력을 확인할 수 있다.

```Shell
$ kubectl describe node docker-desktop
...
  Namespace                   Name                                      CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                      ------------  ----------  ---------------  -------------  ---
  default                     queue-678d47565-8zrxc                     0 (0%)        0 (0%)      3000Mi (38%)     0 (0%)         4m2s
  default                     queue-678d47565-z9fzv                     0 (0%)        0 (0%)      3000Mi (38%)     0 (0%)         23s
  kube-system                 coredns-76f75df574-jn6wn                  100m (1%)     0 (0%)      70Mi (0%)        170Mi (2%)     29d
  kube-system                 coredns-76f75df574-n9mhn                  100m (1%)     0 (0%)      70Mi (0%)        170Mi (2%)     29d
  kube-system                 etcd-docker-desktop                       100m (1%)     0 (0%)      100Mi (1%)       0 (0%)         29d
  kube-system                 kube-apiserver-docker-desktop             250m (3%)     0 (0%)      0 (0%)           0 (0%)         29d
  kube-system                 kube-controller-manager-docker-desktop    200m (2%)     0 (0%)      0 (0%)           0 (0%)         29d
  kube-system                 kube-proxy-2t2nw                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         29d
  kube-system                 kube-scheduler-docker-desktop             100m (1%)     0 (0%)      0 (0%)           0 (0%)         29d
  kube-system                 storage-provisioner                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         29d
  kube-system                 vpnkit-controller                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         29d
...
```

- 위를 보면 큐 2개가 있고 두 컨테이너가 메모리를 많이 차지하고 있음을 알 수 있다.
- 여기서 조심해야 할 것은 컨테이너가 저만큼 메모리를 사용 중인 것이 아니라 저 메모리를 사용할 수 있도록 보장한 것이라는 것이다.
- 이제 3개를 배포하고 포드를 확인하면 다음과 같다.

```Shell
$ kubectl get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/queue-678d47565-2mth8   0/1     Pending   0          2s
pod/queue-678d47565-8zrxc   1/1     Running   0          7m14s
pod/queue-678d47565-z9fzv   1/1     Running   0          3m35s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   29d

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/queue   2/3     3            2           7m14s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/queue-678d47565   3         3         2       7m14s
```

- 하나가 Pending 된 것을 확인할 수 있다.
- Pending된 노드를 describe로 확인해보면 아래와 같이 메모리 부족으로 실패한 메시지를 볼 수 있다.

```Shell
...
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  85s   default-scheduler  0/1 nodes are available: 1 Insufficient memory. preemption: 0/1 nodes are available: 1 No preemption victims found for incoming pod
```

- 이때 쿠버네티스는 메모리를 다 사용하게 된 것은 아니고 세 번째 포드를 제외한 두 개의 포드 메모리만 사용한다.
- 또한 이전 강의에서 사용했던 클러스터를 사용하면 클러스터가 적절히 메모리가 비어있는 다른 노드에 배포한다.

#### CPU Request

- 또한 CPU에 대한 요청을 명시할 수도 있다.
- 현재 내 도커 데스크탑은 8개의 CPU를 가지고 있다.

```yaml
...
  template: # template for the pods
    metadata:
      labels:
        app: queue
    spec:
      containers:
      - name: queue
        image: richardchesterwood/k8s-fleetman-queue:release2
        resources:
          requests:
            memory: 300M  # 1Mi = 1024ki, 1ki = 1024 bytes
            cpu: 0.1
```

- 위처럼 cpu의 자원을 명시적으로 요청할 수 있다.
- 메모리와 마찬가지로 요청한 자원을 항상 다 사용하는 것이 아니며 제한하지도 않는다.
- 노드는 cpu를 많이 사용하지 않는다. 그렇기에 1보다는 소수점이나 m 단위의 요청을 많이 한다. 자세한건 [쿠버네티스 공식문서](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-units-in-kubernetes)를 참고하면 된다.
    - 1, 2, 3 등은 CPU의 개수
    - 10m = 10 / 1000 = 0.01 이다.
- 메모리와 마찬가지로 자원을 넘어서는 요청을 한다면 pending 된다.

### Resource Limit

- 리소스 요청은 스케줄러가 합리적인 선택을 할 수 있도록 도와주는 도구이다.
- 하지만 요청된 자원을 넘어간다고 제한하거나 알림을 주지 않는다.

```yaml
...
  template: # template for the pods
    metadata:
      labels:
        app: queue
    spec:
      containers:
      - name: queue
        image: richardchesterwood/k8s-fleetman-queue:release2
        resources:
          requests:
            memory: 300M  # 1Mi = 1024ki, 1ki = 1024 bytes
            cpu: 0.1
        limits:
          memory: 500mi
          cpu: 200m  # 0.2와 동일
```

- 위처럼 자원 요청과 마찬가지로 제한한는 자원의 한계를 명시하면 된다.
- 그런데 제한이 메모리와 cpu에 적용되는 방식이 조금 다르기에 이를 잘 이해해야 한다.
  - 메모리
    - 실행 중인 컨테이너가 사용하는 실제 메모리가 제한치를 초과한다면 해당 컨테이너는 작동을 종료한다.
    - 이는 포드가 종료됨을 의미하는 것이 아니라 컨테이너가 종료되었다가 포드를 통해 재시작됨을 의미한다.
    - 예를 들어 6개월에 한 번 정도 메모리 누수가 생겨서 이를 처리해줘야 한다면 누수 자체를 고쳐도 되지만 리소스가 부족할 때 제한을 이용해 재시작하는 방법도 있다.
    - 물론 위 예시는 극단적인 상황이며 최대한 지양해야 한다.
  - cpu
    - 컨테이너 자체가 런타임에서 사용하는 cpu와 연관되어 있다.
    - 만약 cpu가 제한을 넘어가면 컨테이너가 종료되지 않고 계속 작동하지만 제한된다.
- 이러한 제한이 실질적으로 동작하는 것은 쿠버네티스나 도커가 아니라 `cgroups` 라는 리눅스 기술이다.


## Section 26: Gathering Metrics

- `kubectl top {node/pod}` 명령어로 포드와 노드의 cpu 사용량을 확인할 수 있다.
- 하지만 명령어를 실행하면 `error: Metrics API not available` 이런 에러가 발생한다.
- 이는 메트릭스 서버가 활성화되지 않았기 때문이다.
- 메트릭스 서버는 클러스터에서 사용할 또 다른 포드와 마찬가지로 kube-system 네임스페이스에서 메트릭스를 모아주는 역할을 한다.
- 메트릭스 서버가 실행되어도 기본 1분은 정보를 수집하기 때문에 대기해야 한다.

- 강의는 minikube 기준으로 알려줬기에 addon만 추가하면 되지만 docker-desktop은 파일을 받아 직접 배포해야 한다.
- 이에 대한 정리는 [이 블로그](https://dev.to/docker/enable-kubernetes-metrics-server-on-docker-desktop-5434)를 참고하면 된다.
  - 파일의 내용이 이미지와 조금 다르지만 포스트 내용과 동일하게 `--kubelet-insecure-tls` 를 추가하면 잘 동작한다.
  - [kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server/releases) 여기에서 파일을 직접 받으면 된다. 위 플래그는 동일하게 추가해야 한다.

> #### `kubelet-insecure-tls`
> 
> - 이 플래그는 메트릭스 서버와 kubelet(kubernetes 노드 에이전트)의 통신 관련 보안 문제를 해결하기 위한 방법이다.
> - 이 플래그는 메트릭 서버가 kubelet과 통신할 때 안전하지 않은 TLS 연결을 사용할 수 있도록 만든다.
> - 이는 kubelet이 기본적으로 유효하고 신뢰할 수 있는 TLS 인증서를 요구하지만 Docker Desktop과 같은 환경에는 kubelet에 제대로 구성된 인증서가 없을 수 있기 때문이다.
> - 물론 이는 보안을 약화시키기에 프로덕션 환경에선 권장되지 않는다.
> - 그렇기에 개발이나 테스트 환경에서만 사용하는 것이 좋다.


### 자바 스프링부트 앱 조정, 힙 제한

- 강의에서 주어진 마이크로서비스들의 메모리 사용량을 보면 효울적이진 않다.
- 이는 강사가 심화까지 고려하고 만든 서비스가 아니기 때문이다.


